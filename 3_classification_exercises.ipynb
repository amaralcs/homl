{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RELOAD=True mode to import pickles and avoid retraining models \n",
    "from joblib import dump, load\n",
    "model_fpath = 'saved_models/3_'\n",
    "RELOAD = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1)\n",
    "Build a classifier for the MNIST dataset tha achieves over 97% accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RELOAD:\n",
    "    mnist = load(model_fpath+'mnist.joblib')\n",
    "else:\n",
    "    mnist = fetch_openml('mnist_784', version=1)\n",
    "    dump(mnist, model_fpath+'mnist.joblib')\n",
    "\n",
    "X, y = mnist['data'], mnist['target'].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall data is already shuffled into training and test set\n",
    "X_train, y_train, X_test, y_test = X[:60000], y[:60000], X[60000:], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with a small set and to write the code and then run on the full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small, y_train_small = X_train[:5000], y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   26.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_preds = cross_val_predict(knn_clf, X_train_small, y_train_small, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def print_model_scores(y_actual, y_preds, average=None):\n",
    "    precision = precision_score(y_actual, y_preds, average=average)\n",
    "    recall = recall_score(y_actual, y_preds, average=average)\n",
    "    f1 = f1_score(y_actual, y_preds, average=average)\n",
    "\n",
    "    print('Model results')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results\n",
      "Precision: 0.9252946891621784\n",
      "Recall: 0.9202217478956463\n",
      "F1: 0.9215018037617095\n"
     ]
    }
   ],
   "source": [
    "print_model_scores(y_train_small, knn_preds, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'n_neighbors': array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                          'weights': ['uniform', 'distance']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'weights': ['uniform', 'distance'], 'n_neighbors': np.r_[1:10]}\n",
    "]\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=3)\n",
    "grid_search.fit(X_train_small, y_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_clf = grid_search.best_estimator_\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results\n",
      "Precision: 0.9316239364223113\n",
      "Recall: 0.9279879556944662\n",
      "F1: 0.9289948152946156\n"
     ]
    }
   ],
   "source": [
    "grid_preds = cross_val_predict(grid_clf, X_train_small, y_train_small, cv=3)\n",
    "print_model_scores(y_train_small, grid_preds, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search on this model trained with a small sample slightly improved results and yields n_neighbours = 4. With this, I can reduce the search space for n_neighbors to say range(3, 6) for the full dataset to save some time during training as the full dataset is very large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating GridSearch\n",
      "GridSearch complete in 568.43 minutes\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-694fdb3bc841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'GridSearch complete in {(time.time()-start_time)/60.0:.2f} minutes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgrid_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Found best params {grid_search.best_params}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator'"
     ]
    }
   ],
   "source": [
    "# Grid Search for full dataset\n",
    "if RELOAD:\n",
    "    grid_search = load(model_fpath + 'ex1_knn.joblib')\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    param_grid = [{'weights':['uniform', 'distance'], 'n_neighbors':np.r_[3:7]}]\n",
    "    print(\"Initiating GridSearch\")\n",
    "    grid_search = GridSearchCV(knn_clf, param_grid, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f'GridSearch complete in {(time.time()-start_time)/60.0:.2f} minutes')\n",
    "    dump(grid_search, model_fpath+'ex1_knn.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best params {'n_neighbors': 4, 'weights': 'distance'}\n",
      "Initiating CrossValPredict on training set\n",
      "Validation completed in 800.63 minutes\n",
      "Model results\n",
      "Precision: [0.97985012 0.96184739 0.98721934 0.96971193 0.97932233 0.96290829\n",
      " 0.97712855 0.96174433 0.97943123 0.94711618]\n",
      "Recall: [0.9934155  0.99466034 0.95938234 0.96085467 0.9647381  0.96255303\n",
      " 0.98901656 0.97509976 0.93590839 0.96335519]\n",
      "F1: [0.98658618 0.97797871 0.9731018  0.96526299 0.97197551 0.96273063\n",
      " 0.98303661 0.968376   0.95717532 0.95516667]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "grid_clf = grid_search.best_estimator_\n",
    "print(f'Found best params {grid_search.best_params_}')\n",
    "\n",
    "print(f'Initiating CrossValPredict on training set')\n",
    "grid_preds = cross_val_predict(grid_clf, X_train, y_train, cv=3)\n",
    "print(f'Validation completed in {(time.time()-start_time)/60.0:.2f} minutes')\n",
    "print_model_scores(y_train, grid_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_preds = cross_val_predict(grid_clf, X_test, y_test, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results\n",
      "Precision: 0.9421027040033261\n",
      "Recall: 0.9402735042228934\n",
      "F1: 0.9407514123508827\n"
     ]
    }
   ],
   "source": [
    "print_model_scores(y_test, test_set_preds, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model is slightly overfitting the train set. Perhaps scaling can help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
