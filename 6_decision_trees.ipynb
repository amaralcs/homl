{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "We'll start by building a decision tree and examining how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "import numpy as np\n",
    "\n",
    "chapter_imgs = 'images/decision_trees/'\n",
    "# IFrame(src='./nice.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] # petal length and width\n",
    "y = iris.target\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "import os \n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"351pt\" height=\"314pt\"\n",
       " viewBox=\"0.00 0.00 351.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-310 347,-310 347,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M209.5,-306C209.5,-306 65.5,-306 65.5,-306 59.5,-306 53.5,-300 53.5,-294 53.5,-294 53.5,-235 53.5,-235 53.5,-229 59.5,-223 65.5,-223 65.5,-223 209.5,-223 209.5,-223 215.5,-223 221.5,-229 221.5,-235 221.5,-235 221.5,-294 221.5,-294 221.5,-300 215.5,-306 209.5,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal length (cm) &lt;= 2.45</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.667</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 150</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [50, 50, 50]</text>\n",
       "<text text-anchor=\"middle\" x=\"137.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e58139\" stroke=\"#000000\" d=\"M105,-179.5C105,-179.5 12,-179.5 12,-179.5 6,-179.5 0,-173.5 0,-167.5 0,-167.5 0,-123.5 0,-123.5 0,-117.5 6,-111.5 12,-111.5 12,-111.5 105,-111.5 105,-111.5 111,-111.5 117,-117.5 117,-123.5 117,-123.5 117,-167.5 117,-167.5 117,-173.5 111,-179.5 105,-179.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [50, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M109.8696,-222.8796C102.4237,-211.6636 94.3575,-199.5131 86.8718,-188.2372\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"89.7273,-186.2104 81.2805,-179.8149 83.8954,-190.082 89.7273,-186.2104\"/>\n",
       "<text text-anchor=\"middle\" x=\"76.33\" y=\"-200.6199\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#ffffff\" stroke=\"#000000\" d=\"M286,-187C286,-187 147,-187 147,-187 141,-187 135,-181 135,-175 135,-175 135,-116 135,-116 135,-110 141,-104 147,-104 147,-104 286,-104 286,-104 292,-104 298,-110 298,-116 298,-116 298,-175 298,-175 298,-181 292,-187 286,-187\"/>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">petal width (cm) &lt;= 1.75</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 50, 50]</text>\n",
       "<text text-anchor=\"middle\" x=\"216.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M165.1304,-222.8796C170.93,-214.1434 177.1059,-204.8404 183.0908,-195.8253\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.1368,-197.5652 188.7517,-187.2981 180.3049,-193.6935 186.1368,-197.5652\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.7022\" y=\"-208.103\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#4de88e\" stroke=\"#000000\" d=\"M196,-68C196,-68 99,-68 99,-68 93,-68 87,-62 87,-56 87,-56 87,-12 87,-12 87,-6 93,0 99,0 99,0 196,0 196,0 202,0 208,-6 208,-12 208,-12 208,-56 208,-56 208,-62 202,-68 196,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.168</text>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 54</text>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 49, 5]</text>\n",
       "<text text-anchor=\"middle\" x=\"147.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M190.8069,-103.9815C185.3469,-95.1585 179.5716,-85.8258 174.0793,-76.9506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"176.942,-74.9254 168.7035,-68.2637 170.9896,-78.609 176.942,-74.9254\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#843de6\" stroke=\"#000000\" d=\"M331,-68C331,-68 238,-68 238,-68 232,-68 226,-62 226,-56 226,-56 226,-12 226,-12 226,-6 232,0 238,0 238,0 331,0 331,0 337,0 343,-6 343,-12 343,-12 343,-56 343,-56 343,-62 337,-68 331,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.043</text>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 46</text>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 1, 45]</text>\n",
       "<text text-anchor=\"middle\" x=\"284.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M241.8207,-103.9815C247.2016,-95.1585 252.8932,-85.8258 258.3059,-76.9506\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"261.3851,-78.6236 263.6038,-68.2637 255.4088,-74.9789 261.3851,-78.6236\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7fddcea9d978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source\n",
    "\n",
    "export_graphviz(\n",
    "    tree_clf, \n",
    "    out_file= os.path.join(IMAGES_PATH, \"iris_tree.dot\"),\n",
    "    feature_names=iris.feature_names[2:],\n",
    "    class_names=iris.target_names,\n",
    "    rounded=True,\n",
    "    filled=True\n",
    ")\n",
    "\n",
    "Source.from_file(os.path.join(IMAGES_PATH, \"iris_tree.dot\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the diagram above we can see how the decision tree makes a prediction. \n",
    "\n",
    "Suppose we find an iris flower with petal width <= 0.8cm. The first node evaluates to true, we move to a leaf node and find our class.\n",
    "\n",
    "However if we find a flower with petal width >0.8 we move to the next node on the right. It is not a leaf node so we ask another question: is the petal width <= 1.75cm? If so we classify it as versicolor otherwise as virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: One of the advantages of decision trees is that they need little to no data preparation, feature scaling or centering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note that each node has various attributes. Here's their definition\n",
    "\n",
    "**samples:** How many training instances it applies to. E.g. 100 instances have petal width >= 0.8cm (depth 1, right) and of those 54 have petal width <= 1.75cm and 46 greater than that.\n",
    "\n",
    "**value:** How many training instances of each class this node applies to. E.g. bottom right (purple) node applies to 0 *iris setosa*, 1 *iris versicolor* and *45 iris virginica*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **gini** attribute measures how *pure* a node is. A node is pure (gini=0) if all training instances it applies to belong to the same class.\n",
    "\n",
    "For example the orange node has gini=0 because all training instances are *iris setosa* instances. More formally, the Gini impurity is defined as\n",
    "\n",
    "$$ G_i = 1 - \\sum^{n}_{k=1}p_{i,k}^2$$\n",
    "\n",
    "Where $p_{i,k}$ is the ratio of class $k$ instances among the training instances in the $i^{th}$ node\n",
    "\n",
    "For example, the green node has gini score equal to\n",
    "$$ 1 - (0/54)^2 - (49/54)^2 - (5/54)^2 \\approx 0.168 $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = [0.00, 0.33, 0.66, 1.00]\n",
    "c_colors = ['#9898ff', '#a0faa0', '#fafab0']\n",
    "cscale = sorted(\n",
    "    [(val, c) for val,c in zip(scale, c_colors)] +\n",
    "    [(val, c) for val,c in zip(scale[1:], c_colors)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.validators.scatter.marker import SymbolValidator\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, fname, axes=[0, 7.5, 0, 3], iris=True, \n",
    "                           legend=False, plot_training=True, target_names=iris['target_names']):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = tree_clf.predict(X_new).reshape(x1.shape)\n",
    "    \n",
    "    scale = [0.00, 0.33, 0.66, 1.00]\n",
    "    c_colors = ['#9898ff', '#a0faa0', '#fafab0']\n",
    "    cscale = sorted(\n",
    "        [(val, c) for val,c in zip(scale, c_colors)] +\n",
    "        [(val, c) for val,c in zip(scale[1:], c_colors)]\n",
    "    )\n",
    "    \n",
    "    fig = go.Figure(\n",
    "        go.Contour(\n",
    "            x = x1s, y = x2s, z = y_pred,\n",
    "            showscale = False, opacity = 0.3,\n",
    "            colorscale = cscale),\n",
    "        layout=go.Layout(\n",
    "            title = 'Decision Tree boundaries',\n",
    "            font=dict(\n",
    "                family=\"Courier New, monospace\",\n",
    "                size=18,\n",
    "                color=\"#7f7f7f\"))\n",
    "    )\n",
    "    if not iris:\n",
    "        c_colors = sorted([\"#7d7d58\", \"#4c4c7f\", \"#507d50\"])\n",
    "        cscale = sorted(\n",
    "            [(val, c) for val,c in zip(scale, c_colors)] +\n",
    "            [(val, c) for val,c in zip(scale[1:], c_colors)]\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Contour(\n",
    "                x = x1s, y = x2s, z = y_pred,\n",
    "                showscale = False, opacity = 0.3,\n",
    "                colorscale = cscale,\n",
    "                contours_coloring='lines'))\n",
    "\n",
    "    if iris:\n",
    "        fig.update_layout(xaxis_title='Petal length', yaxis_title='Petal width')\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[1.4, 3.2, 4.05],\n",
    "                y=[1.0, 1.8, 0.5],\n",
    "                mode=\"text\",\n",
    "                text=[\"Depth=0\", \"Depth=1\", \"Depth=2\"],\n",
    "                showlegend=False))\n",
    "        fig.add_scatter(\n",
    "            x = [2.45, 2.45], y=[0, 3], showlegend=False, mode='lines',\n",
    "            line=dict(width=2, color='black')\n",
    "        )\n",
    "        fig.add_scatter(\n",
    "            x = [2.45, 7.5], y=[1.75, 1.75], showlegend=False, mode='lines',\n",
    "            line=dict(dash='dot', width=2, color='black')\n",
    "        )\n",
    "    else:\n",
    "        fig.update_layout(xaxis_title='$x_1', yaxis_title='$x_2$')\n",
    "    if plot_training:\n",
    "        num_classes = len(target_names)\n",
    "        symbols = SymbolValidator().values[:8*num_classes:8]\n",
    "        colors = ['blue', 'green', 'orange']\n",
    "        for idx, species, symb, c in zip(range(num_classes), target_names, symbols, colors):\n",
    "            fig.add_scatter(\n",
    "                x = X[:, 0][y == idx],\n",
    "                y = X[:, 1][y == idx],\n",
    "                name = species, \n",
    "                mode = 'markers', marker_symbol = symb, marker_color = c\n",
    "            )\n",
    "        fig.write_html(chapter_imgs + fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"600\"\n",
       "            src=\"images/decision_trees/iris_boundaries.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fddc37de080>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_decision_boundary(tree_clf, X, y, fname='iris_boundaries.html')\n",
    "IFrame(src=chapter_imgs+'iris_boundaries.html', width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image above we can see the decision tree boundaries. The solid black line represents the split of the root node. Since the blue area is pure, it cannot be split any further. \n",
    "\n",
    "The decision tree then performs it's second split at width=1.75, represented by the dotted line. Since we set max depth=2, there are no more splits, however increasing depth increases the fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees are an example of a *White box* model. It is easy to understand and explain why it makes its decision. In contrast, Random Forests and Neural Nets are highly accurate, but very hard to explain, and are called *black box* models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees can estimate the probability an instance belongs to a class *k* as follows.\n",
    "\n",
    "- Traverse to the the leaf node for this instance\n",
    "- Return ratio of training instances of class *k* in this node\n",
    "\n",
    "For example, if we found a flower with petal length 5 and petal width 1.5 we get the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class setosa probability: 0.000\n",
      "Class versicolor probability: 0.907\n",
      "Class virginica probability: 0.093\n",
      "Prediction class:  [1]\n"
     ]
    }
   ],
   "source": [
    "for proba, cls in zip(tree_clf.predict_proba([[5, 1.5]])[0], iris['target_names']):\n",
    "    print(f'Class {cls} probability: {proba:0.3f}')\n",
    "    \n",
    "print(\"Prediction class: \", tree_clf.predict([[5, 1.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that any new instance that probabilities are identical for any instance located in a leaf node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CART algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn uses the *Classification and Regression Tree* algorithm. It works as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the training set in two using a single feature $k$ and threshold $t_k$. To choose $k$ and $t_k$, search for the pair $(k, t_k)$ that produces the purest subsets (wieghted by size). The equation to be minimized is \n",
    "\n",
    "$$ J(k, t_k) = \\frac{m_{\\text{left}}}{m}G_{\\text{left}} + \\frac{m_{\\text{right}}}{m}G_{\\text{right}} $$\n",
    "\n",
    "where $$\\begin{cases} \n",
    "        G_{\\text{left/right}} & \\text{measures the impurity of the left/right subset}\\\\\n",
    "        m_{\\text{left/right}} & \\text{number of instances on the left/right subset}\n",
    "        \\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this first split is done, it recursively splits the subsets using the same logic, stopping recusion once it reaches maximum depth (hyperparameter) or it cannot find a split that will reduce impurity.\n",
    "\n",
    "Some other parameters that control stopping conditions are *min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_leaf_nodes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CART Algorithm is an example of a greedy algorithm. It searches for the optimal split at the top leve, not caring whether that will happen several splits later. A greedy algorithm produces a solution that is good, but not guaranteed to be optimal. Finding the optimal tree is known to be an NP-Complete problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a prediction, we need to traverse a tree. Decision Trees are approximately balanced thus has roughly $O(\\log_2{m})$ nodes. Since each node requires only checking one feature, the overall complexity is $O(\\log_2{m})$. Thus predictions are very fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm compares at most all features (less if *max_features* is set). It does so on all samples at each node resulting in $O(n\\times m\\log_2{m})$ complexity.\n",
    "\n",
    "For small training sets, you can pre-sort the data (pre-sort=True), but this slows down training considerably for large training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
