{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "\n",
    "model_dir = 'saved_models/12_custom_models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have used tf.keras mainly. That is usually enough for 95% of time, however if you need to dive deeper, you can use Tensorflow's lower level API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A quick tour of Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some characteristics of the TensorFlow API:\n",
    "\n",
    "- Its core is very similar to Numpy, but with GPU support\n",
    "- Supports distributed computing\n",
    "- Its compiler allows for optimization of computing speed and memory usage. It works by extracting the *computation graph* from a Python function then optimizing it, and finally running it.\n",
    "- Computation graphs are portable, meaning you can train models in one environment (e.g Python) and run it in another (e.g. Java or Android)\n",
    "- Implements autodiff and provides excellent standard optimizers such as RMSPROP and Nadam\n",
    "\n",
    "It also has features for loading and preprocessing data (tf.data, tf.io), image processing (tf.image), signal processing (tf.signal) and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is at the center of an extensive ecosystem of libraries. TensorBoard allows for vizualization, TensorFlow Extended (TFX) is a set of libraries built to productionize TensorFlow Projects, including tools for data validation, preprocessing, model analysis and serving. TensorFlow Hub provides a way to download and share pretrained neural networks. Finally you can check [TensorFlow Resources](https://www.tensorflow.org/resources) and this [github pages](https://github.com/jtoy/awesome-tensorflow) for more TensorFlow-based projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TensorFlow like Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor is usually a multidimensional array (just like numpy's ndarray), but it can also hold a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ```tf.constant()``` to create a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing is the same as Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the @ to perform matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.linalg.matmul(t, tf.transpose(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find all basic math operations and most numpy operations in TensorFlow. Some might have a different name (e.g. np.mean() = tf.reduce_mean()). When the name differs, there is a good reason for it. For example for tf.reduce_sum(), the GPU implementation does not guarantee the order in which elements are added, so for 32-bit floats the result may change ever so slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a tensor from a numpu array and vice versa. You can even apply TF operations to a numpy array and numpy operations to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that NumPy uses 64-bit precision by default while TensorFlow uses 32-bit. This is because 32-bit is generally more than enough for Neural Nets and it runs faster while using less RAM. When you create a tensor from a NumPy array, set ```dtype=float32```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow does not execute automatic type conversions. It raises an exception if you try to execute an operation on tensors with incompatible types. For example you cannot add a float tensor and an integer tensor, nor add a 32-bit float and a 64-bit float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    tf.constant(2.) + tf.constant(40)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use tf.cast if you really need to convert types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(2.) + tf.cast(tf.constant(40), tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```tf.Tensor``` values we have seen so far are immutable. Thus we cannot use regular tensors to implement weights in a NN since they need to be tweaked by backpropagation. For this we can use ```tf.Variable```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables can be modified using the ```assign()``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[3., 4., 5.],\n",
       "       [6., 7., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 + v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[3., 4., 5.],\n",
       "       [6., 7., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the other structures available are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sparse tensors* (tf.SparseTensor)\n",
    "\n",
    "Efficiently represent tensors containing mostly zeros. tf.sparse contains operations for these tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tensor Arrays* (tf.TensorArray)\n",
    "\n",
    "Lists of tensors. Have fixed size by default but can optionally be made dynamic. All tensors they contain must have the same shape and data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ragged tensors* (tf.RaggedTensor)\n",
    "\n",
    "Static lists of tensors, where every tensor has the same shape and data type. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*String tensors*\n",
    "\n",
    "Regular tensors of type tf.string. These are byte strings, not unicode strings. Creating a tensor using a Unicode string automatically converts them to UTF-8. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sets*\n",
    "\n",
    "Are represented as regular (or sparse) tensors. For example ```tf.constant([[1,2], [3,4]])``` represents the two sets {1,2} and {3,4}. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Queues*\n",
    "\n",
    "Store tensors across multiple steps. TensorFlow offers various kinds of queues: FIFO, PriorityQueues, RandomShuffleQueue) and batch items of different shapes by padding (PaddingFIFOQueue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next example, let's suppose we want to create a regression model but the training set is noisy. If we use MSE as the loss functions, we will penalize large errors too much causing the model to be imprecise. Mean Absolute error fixes that but the model might take a while to converge and the trained model might not be very precise. \n",
    "\n",
    "We propose using the Huber loss (introduced in chapter 10). It is not implemented in Keras by default but it is in tf. keras, we can use ```keras.losses.Huber```. Let's pretend it is not implemeted and create our own Huber loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error)/2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this loss when creating and compiling a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5612 - mae: 0.9172 - val_loss: 0.3074 - val_mae: 0.5954\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2103 - mae: 0.5022 - val_loss: 0.2643 - val_mae: 0.5473\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(loss=huber_fn, optimizer='nadam', metrics=['mae'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n",
    "model.save(model_dir + 'my_model_with_custom_loss.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what happens to the loss when we save and load up the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Models with Custom Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading a model containing a custom object (such as a function), we need to map the names to the objects using a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_dir + 'my_model_with_custom_loss.h5', \n",
    "                                   custom_objects={'huber_fn':huber_fn})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above implementation of the huber function has the threshold $\\delta$ automatically set to 1, what if we want to add a custome threshold? If we use the method above, saving the model does not change the threshold. We can solve this by creating a subclass of ther keras.losses.Loss class and implementing the ```get_config()``` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use an instance of this class when compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2318 - mae: 0.4960 - val_loss: 0.2923 - val_mae: 0.5115\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2215 - mae: 0.4859 - val_loss: 0.2308 - val_mae: 0.4779\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=HuberLoss(threshold=2.), optimizer='nadam', metrics=['mae'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_valid_scaled, y_valid))\n",
    "model.save(model_dir + 'my_model_with_custom_loss_class.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then when loading the class we follow the same procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_dir + 'my_model_with_custom_loss_class.h5', \n",
    "                                   custom_objects={'HuberLoss':HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Activation Functions, Initializers, Regularizers and Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of Keras functionality can be customized in a similar manner, you will just need to write a simple function with the appropriate inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of a custom softplus (```keras.activations.softplus()``` or ```tf.nn.softplus()```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom Glorot Initializer (```keras.initializers.glorot_normal()```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A $l_1$ regularizer (```keras.regularizers.l1(0.01)```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a custom constraint that ensures all weights are positive (```keras.constraints.nonneg()``` or ```tf.relu()```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_positive_weights(weights):\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these to define a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(30, activation=my_softplus,\n",
    "                              kernel_initializer=my_glorot_initializer,\n",
    "                              kernel_regularizer=my_l1_regularizer,\n",
    "                              kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a function has a hyperparameter that needs to be saved with the model, then we need to subclass the appropriate class. For example ```keras.regularizers.Regularizer```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(tf.keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor=factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {'factor':self.factor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Losses and metrics are conceptually not the same thing; Losses (e.g. cross-entropy) are used by Grad Desc. to *train* a model, hence they need to be smooth and their gradients should not be 0 everywhere. It is also ok if they're not easily interpretable by humans. Metrics on the other hand (e.g. accuracy), are used to *evaluate* a model, they must be easily interpretable and don't have other restrictions.\n",
    "\n",
    "We can however, use define custom metrics the same way we define a custom loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing so, for each batch during training, keras will compute the metric and keep track of its mean since the beginning of the epoch. Most of the time this is fine, but not always!\n",
    "\n",
    "For example, if we're considering a binary classifier's precision we don't want this to happen. Suppose the model made five positive prediction in the first batch, four of which were correct (80% precision). Then, suppose the model made three positive predictions in the second batch, but they were incorrect (0% precision). If you compute the mean over the two batches we get 40% precision, but that's **not** right! Indeed, there were a total of four true positives (4+0) out of eight predictions (5+3), so the overall precision is 50%.\n",
    "\n",
    "We replicate the above example with a slight modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a ```Precision``` objecte and use it like a function, passing the labels and predictions for the first and second batch. The ```Precision``` object created above is a *streaming metric* (or *stateful metric*), it is gradually updated batch after batch.\n",
    "\n",
    "We can call ```result()``` to get the current value of the metric and look at its variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a streaming metric, we subclass the keras.metrics.Metric class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn\n",
    "\n",
    "class HuberLoss(tf.keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight('total', initializer='zeros')\n",
    "        self.count = self.add_weight('count', initializer='zeros')\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom layers can be used to create new exotic layers that do not have a default implementation. They can also be used to simplify the creation of a repetitive architecture, containing identical blocks of layers. For example if the model is a sequence of layers A, B, C, A, B, C, A, B, C, you might want to define a custom layer D containing layers A,B,C. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a a simple layer without weights (such as a ```Flatten()``` layer) you can wrap a function around a keras.layers.Lambda layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = tf.keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be used like any other layer with the Sequential, functional or Subclassing API. You could also use it as an activation layer. \n",
    "\n",
    "Let's create an implementation of a Dense Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel', shape=[batch_input_shape[-1], self.units],\n",
    "            initializer='glorot_normal')\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias', shape=[self.units], initializer='zeros')\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "    \n",
    "    def call(self, X):\n",
    "        self.activation(X @ self.kernel + self.bias) # matrix mult\n",
    "        \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + self.units)\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'units': self.units,\n",
    "                'activation':keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For layers with multiple inputs (e.g. concatenate) the argument to the call() method should be a tuple containing all inputs and similarly the argument to the compute_output_shape() method should be a tuple containing each input's batch shape. The following toy layer takes two inputs and returns three outputs.\n",
    "\n",
    "Note the layer can only be used with the Functional and Subclassing API but not the Sequential(which accepts layers with one input and one output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(tf.keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        return [X1 + X2, X1 * X2, X1 / X2]\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        b1, b2 = batch_input_shape\n",
    "        return [b1, b1, b1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For layers with different behaviour in training and test (e.g. dropout), we need to pass a ```training``` parameter to the call() method and decide what to do. The following layer adds Gaussian noise during training (for regularization) but does nothing during testing (tf.keras.layers.GaussianNoise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGaussianNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev=stddev\n",
    "        \n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "    def comput_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example we will create the model defined in figure 12-3 (pg 395)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs go through a first dense layer then through a *residual block* composed of two dense layers and an addition operation, then through the same residual block three more times, then through a second residual block and the final result goes through a dense output layers. \n",
    "\n",
    "Note: this is just an example model. \n",
    "\n",
    "Let's start by creating a ResidualBlock Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(n_neurons, activation='elu',\n",
    "                                             kernel_initializer='he_normal')\n",
    "                       for _ in range(n_layers)]\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras automatically detects that the ```hidden``` attribute contains trackable objects so their variables are automatically added to the layer's list of variables. Now, for the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = tf.keras.layers.Dense(30, activation='elu',\n",
    "                                             kernel_initializer='he_normal')\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works as any other methods we used previously. If you want to save and load the model you must implement the get_config() methods for both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model class is a subclass of the Layer class, so models can be defined and used exactly like layers, but model have extra functionality (compile, predict, fit etc..). Note: You could define every layer as a model, since they're (almost) same thing, but it is cleaner to define the internal components of the model (i.e. the layers) from the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and Metrics based on Internal Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom losses defined earlier were all based on the labels and predictions. Sometimes, you'll want to define custom losses based on other parts of the model, such as weights or activations of hidden layers. This can be useful for regularization or to monitor internal aspects of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define a custom loss on model internals, compute it based on the part you want it then pass the result to the add_loss() method. \n",
    "\n",
    "In the example below we build a custom regression MLP composed of a stack of five hidden layers + output layer. This model will have an auxiliary output on top of the upper hidden layer. The loss associated to this auxiliary output will be called the *reconstruction loss*: the mean squared difference between the reconstruction and the inputs. \n",
    "\n",
    "By adding this loss, we encourage the model to preserve as much information as possible through the hidden layers. In practice, this loss sometimes improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(tf.keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(*kwargs)\n",
    "        self.hidden = [tf.keras.layers.Dense(30, activation='elu',\n",
    "                                            kernel_initializer='lecun_normal')\n",
    "                       for _ in range(5)]\n",
    "        self.out = tf.keras.layers.Dense(output_dim)\n",
    "#         self.reconstruction_mean = tf.keras.metrics.Mean(name='reconstruction_error')\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = tf.keras.layers.Dense(n_inputs)\n",
    "        super().build(batch_input_shape)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "#         if training:\n",
    "#             result = self.reconstruction_mean(recon_loss)\n",
    "#             self.add_metric(result)\n",
    "        return self.out(Z)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the reconstruct layer at the ```build``` method because the number of units must be equal to the number of input units, which is unknown until this method is called.\n",
    "\n",
    "We also scale down the reconstruction loss by multiplying it by 0.05 (another hyperparameter you can tune) so that the reconstruction does not dominate the main loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can similarly define a custom metric and add it using the ```add_metric()``` method. We added this as comment in the function above. Note: there's an issue when calling the fit method below. Perhaps revisit this in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ReconstructingRegressor(1)\n",
    "# model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "# history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "# y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Gradients using Autodiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following function:\n",
    "$$ f(w_1, w_1) = 3w_1^2 + 2w_1w_2 $$\n",
    "We can easily compute its partial derivatives by hand and then evaluate it at a certain point, for instance\n",
    "$$ \\frac{\\partial f}{\\partial w_1} = 6w_1 + 2w_2$$ \n",
    "$$ \\frac{\\partial f}{\\partial w_2} = 2w_1$$ \n",
    "At the point $(w_1, w_2)=(5,3)$ this equates to (36, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However this doesn't scale for neural networks as there are tens of thousands of parameters. Interestingly, one solution is to compute an approximation of each partial by measuring how much the output changes when you perturbate the function by some epsilon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.000003007075065 10.000000003174137\n"
     ]
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3*w1**2 + 2*w1*w2\n",
    "\n",
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "print((f(w1+eps, w2) - f(w1,w2))/eps, (f(w1, w2+eps) - f(w1,w2))/eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good, but again, this is an approximation, and doesn't scale with a large number of parameters.\n",
    "\n",
    "With tensorflow we can do as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "    \n",
    "gradients = tape.gradient(z, [w1, w2])\n",
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GradientTape defines a context to record every operation that involves a variable and then we use the tape to compute the gradient. \n",
    "\n",
    "Note: to save memory only put the strict minimum inside the GradientTape block. You can also pause recording with tape.stop_recording inside the block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tape is also erased after you call its gradient method, so running it again will yield an exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tape was already used!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tape.gradient(z, [w1, w2])\n",
    "except RuntimeError:\n",
    "    print('Tape was already used!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to call gradient more than once you need to make it persistent and delete after use to free resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(36.0, shape=(), dtype=float32) tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "    \n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2)\n",
    "del tape\n",
    "print(dz_dw1, dz_dw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the tape only tracks operations involving *variables*. If you try to put anything else the result will be None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However we can force the tape to watch any tensors to record operations involving them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be useful in cases for example if you want to implement a regularization loss that penalizes activations that vary a lot when the inputs vary little: the loss will be based on the gradient of the activations with regard to the inputs. As the inputs are not variables the tape needs to watch them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to stop gradients to stop form brackpropagating through some part of the NN you can use tf.stop_gradient(). It will return its inputs during the forward pass but does not let gradients through backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3*w1**2 + tf.stop_gradient(2*w1*w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "    \n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical issues can occur when computing gradients, for example the gradients of the my_softplus function for large values yields NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([100.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "    \n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because of floating point arithmetic. To get around this, we can analytically compute the gradient of the softplus $f'(x) = 1/(1+\\exp(x))$ and tell TF to use this stable function to comput gradients. We do that by decorating the function with @tf.custom_gradient and returning its normal output and the function that computes the derivatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1 + 1/exp)\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients\n",
    "\n",
    "x = tf.Variable([100.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "    \n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Training Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to implement different fit methods, for example the one described by the Wide & Deep paper, which needs two different optimizers: one for the wide path and other for the deep path. The default fit methods only uses one optimizer, so we need to write our own custom loop. \n",
    "\n",
    "You may also wanto to create a custom training loop to feel more confident they do precisely what you intend them to do. This can make you feel safer but it comes at the cost of a longer and harder to maintain codebase. Let's do this as an exercise. We start with a simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = tf.keras.regularizers.l2(0.05)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation='elu', kernel_initializer='he_normal',\n",
    "                         kernel_regularizer=l2_reg),\n",
    "    tf.keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a function for randomly sample a batch of instances and a function to display the training status, including number of steps, total number of steps, mean loss since start of epoch and other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)\n",
    "\n",
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the necessary hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = tf.keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = tf.keras.losses.mean_squared_error\n",
    "mean_loss = tf.keras.metrics.Mean()\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Layer dense_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "11610/11610 [==============================] - mean: 1.3684 - mean_absolute_error: 0.5845\n",
      "None\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.7206 - mean_absolute_error: 0.5327\n",
      "None\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.7228 - mean_absolute_error: 0.5342\n",
      "None\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6165 - mean_absolute_error: 0.5064\n",
      "None\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6728 - mean_absolute_error: 0.5263\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Two loops, one for the epochs and another for the batches within each epoch\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        #start by sampling a batch\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True) # Make predictions for this batch\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred)) # compute loss\n",
    "            loss = tf.add_n([main_loss] + model.losses) # sum regularization loss to main loss\n",
    "            \n",
    "        gradients = tape.gradient(loss, model.trainable_variables) # calculate gradient for trainable vars\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables)) # Gradient Descent\n",
    "        # update loss and print status bar\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print(print_status_bar(len(y_train), len(y_train), mean_loss, metrics))\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See pg 405 for more details.\n",
    "\n",
    "This loop does not handle layers that behave differently (e.g. BatchNormalization or Dropout).\n",
    "As seen, there's a lot of room to make errors, but you get full control, choose wisely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow functions and graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining a function to cube a number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass it numbers as well as tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert this function to a TensorFlow Function by passing it to tf.function. Then it will return tensors instead of primitive values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_cube = tf.function(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Under the hood, TensorFlow analyzed the computations performed by the cube function and created an equivalent computation graph. Another way to make this a TF function is to decorate it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, TF optimizes the computation graph, pruning unused nodes, simplifying expressions. As a results, a TF function will usually run much faster than the original Python function, especially for complex computations. Moreover, when you write a custom loss function, metric, layer or any other function, Keras automatically converts it to a TF function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF handles polymorphism by genereating a new graph for each unique set of input shapes. For example, calling ```tf_cube(tf.constant(20))``` will generate a graph for int32 tensors of shape []. If you then call ```tf_cube(tf.constant(10))``` the same graph will be re-used. \n",
    "\n",
    "If you call ```tf_cube(tf.constant([10,20]))``` a new graph will be generated for int32 inputs of shape [2]. This is only true however, when the inputs are tensors. For example calling ```tf_cube(10)``` and ```tf_cube(20)``` will generate two new graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoGraph and Tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See book pg 408 for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Function Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few rules to respect when creating TF functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calls to external libraries (such as numpy and even the standard library) will only happen during tracing. A TF graph can only include TF constructs, so make sure to use tf.reduce_sum() instead of np.sum(), tf.sort() instead of sorted() and so on...\n",
    "\n",
    "Some implications:\n",
    "- If you define a TF function that just returns np.random.rand(), a random number will only be generated when the function is traced. This means f(tf.constant(2.)) and f(tf.constant(3.)) will return the same random number, but f(tf.constant([2., 3.])) will return a different one. Instead use tf.random.uniform([]) and a new random number will be generated upon every call, as the operation will be part of the graph.\n",
    "- If your non-TF function has side effects (e.g. logging or updating a counter), these side effects will not occur every time you call the TF function as they will only occur when the function is traced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make calls to other Python functions of TF functions but they should follow the same rules, as TF will capture their operations in the computation graph. These functions need not be decorated with @tf.function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the function creates a TF variable, it must do so upon the very first call and only then, else you'll get an exceptions. It is better to create variables outside the TF functions (e.g. in the build() method of a custom layer). If you want to assign a new value to the variable, make sure to call its assign() method instead of using the = operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF will only capture for loops that iterate over a tensor or a dataset. So make sure you use ```for i in tf.range(x)```, or the loop will not be captured in the graph. Instead it will run during tracing. (you may want this, if the for loop is meant to build the graph, for example to create each layer in a NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, vectorized implementations are more efficient than for loops!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 12) Implement a custom layer that performs *layer normalization*\n",
    "### Guidelines\n",
    "- The build() method should define two trainable weights $\\alpha$ and $\\beta$, both of shape input_shape[-1:] and data type float32. $\\alpha$ should be initialized with 1s and $\\beta$ with 0s\n",
    "- The call() method should compute the mean $\\mu$ and standard deviation $\\sigma$ of each instance's features. Then the function should compute and return $\\alpha\\otimes(X - \\mu)/(\\sigma + \\epsilon) + \\beta$, where $\\otimes$ is itemwise multiplication (\\*) and $\\epsilon$ is a smoothing term.\n",
    "- Ensure the layer produces the same output (or very nearly the same) as keras.layers.LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon=0.01, **kwargs):\n",
    "        self.epsilon = epsilon\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(name='alpha',\n",
    "                                     shape=batch_input_shape[-1:], \n",
    "                                     trainable=True,\n",
    "                                     initializer=tf.constant_initializer(1.))\n",
    "        self.beta = self.add_weight(name='beta',\n",
    "                                    shape=batch_input_shape[-1:], \n",
    "                                    trainable=True,\n",
    "                                    initializer=tf.constant_initializer(0.))\n",
    "        super().build(batch_input_shape)\n",
    "    \n",
    "    def call(self, X):\n",
    "        mu, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mu)/(tf.sqrt(variance) + self.epsilon) + self.beta\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1254775e-05"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.astype(np.float32) # use california housing dataset from earlier\n",
    "\n",
    "my_layer_norm = MyCustomNormalization()\n",
    "keras_layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(tf.keras.losses.mean_absolute_error(keras_layer_norm(X), my_layer_norm(X))).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty small difference, layer works fine :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 13\n",
    "Train a model using a custom training loop to tackle the Fashion MNIST dataset. \n",
    "- Display the epoch, iteration, mean training loss and mean accuracy over each epoch (updated at each iteration, as well as the validation loss and accuracy at the end of each epoch.\n",
    "- Try using a different optimizer with a different learning rate for the upper layers and the lower layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 10000\n",
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "X_train_full_scaled, X_test_scaled = X_train_full / 255.0, X_test / 255.0\n",
    "X_train_scaled, y_train = X_train_full_scaled[:-validation_size], y_train_full[:-validation_size]\n",
    "X_val_scaled, y_val = X_train_full_scaled[-validation_size:], y_train_full[-validation_size:]\n",
    "\n",
    "assert len(X_train_scaled) > len(X_val_scaled)\n",
    "assert len(X_val_scaled) + len(X_train_scaled) == len(X_train_full_scaled)\n",
    "assert len(y_train) > len(y_val)\n",
    "assert len(y_val) + len(y_train) == len(y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=X_train_scaled.shape[1:]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_training_loop(model, X_train, y_train, X_val, y_val,                    \n",
    "                         epochs=5, batch_size=32,\n",
    "                         optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3),\n",
    "                         loss_fn = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                         mean_loss = tf.keras.metrics.Mean(),\n",
    "                         metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]):\n",
    "    def random_batch(X, y, batch_size=32):\n",
    "        idx = np.random.randint(len(X), size=batch_size)\n",
    "        return X[idx], y[idx]\n",
    "\n",
    "    def progress_bar(iteration, total, size=30):\n",
    "        running = iteration < total\n",
    "        c = \">\" if running else \"=\"\n",
    "        p = (size - 1) * iteration // total\n",
    "        fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "        params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "        return fmt.format(*params)\n",
    "\n",
    "    def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "        metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                             for m in [loss] + (metrics or [])])\n",
    "        end = \"\" if iteration < total else \"\\n\"\n",
    "        print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)\n",
    "    \n",
    "    def reset_metric_state():\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()\n",
    "            \n",
    "    n_steps = len(X_train) // batch_size\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f'Epoch {epoch}/{epochs}')\n",
    "        for step in range(1, n_steps + 1):\n",
    "            X_batch, y_batch = random_batch(X_train, y_train, batch_size=batch_size)\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = model(X_batch, training=True)\n",
    "                main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                loss = tf.add_n([main_loss] + model.losses)\n",
    "            \n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            mean_loss(loss)\n",
    "            for metric in metrics:\n",
    "                metric(y_batch, y_pred)\n",
    "            print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "        print(print_status_bar(len(y_train), len(y_train), mean_loss, metrics))\n",
    "        y_val_pred = model(X_val)\n",
    "        val_loss = mean_loss(loss_fn(y_val, y_val_pred)).numpy()\n",
    "        print(f'Validation {mean_loss.name}: {val_loss}')\n",
    "        reset_metric_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "50000/50000 [==============================] - mean: 0.3832 - sparse_categorical_accuracy: 0.8604\n",
      "None\n",
      "Validation mean: 0.3896506130695343\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - mean: 0.3354 - sparse_categorical_accuracy: 0.8757\n",
      "None\n",
      "Validation mean: 0.35506898164749146\n"
     ]
    }
   ],
   "source": [
    "custom_training_loop(model, X_train_scaled, y_train, X_val_scaled, y_val, epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=X_train_scaled.shape[1:]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal')],\n",
    "    name='lower_layer')\n",
    "lower_optimizer = tf.keras.optimizers.Nadam(lr=1e-3)\n",
    "\n",
    "upper_layers = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')],\n",
    "    name='upper_layer')\n",
    "upper_optimizer = tf.keras.optimizers.SGD(lr=1e-2)\n",
    "model = tf.keras.models.Sequential([lower_layers, upper_layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lower_layer (Sequential)     (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "upper_layer (Sequential)     multiple                  31110     \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=X_train_scaled.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_training_loop2(model, X_train, y_train, X_val, y_val,                    \n",
    "                          epochs=5, batch_size=32,\n",
    "                          optimizers = [],\n",
    "                          loss_fn = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                          mean_loss = tf.keras.metrics.Mean(),\n",
    "                          metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]):\n",
    "    def random_batch(X, y, batch_size=32):\n",
    "        idx = np.random.randint(len(X), size=batch_size)\n",
    "        return X[idx], y[idx]\n",
    "\n",
    "    def progress_bar(iteration, total, size=30):\n",
    "        running = iteration < total\n",
    "        c = \">\" if running else \"=\"\n",
    "        p = (size - 1) * iteration // total\n",
    "        fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "        params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "        return fmt.format(*params)\n",
    "\n",
    "    def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "        metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                             for m in [loss] + (metrics or [])])\n",
    "        end = \"\" if iteration < total else \"\\n\"\n",
    "        print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)\n",
    "    \n",
    "    def reset_metric_state():\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()\n",
    "            \n",
    "    n_steps = len(X_train) // batch_size\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f'Epoch {epoch}/{epochs}')\n",
    "        for step in range(1, n_steps + 1):\n",
    "            X_batch, y_batch = random_batch(X_train, y_train, batch_size=batch_size)\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                y_pred = model(X_batch, training=True)\n",
    "                main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                loss = tf.add_n([main_loss] + model.losses)\n",
    "                for (layer, optimizer) in zip(model.layers, optimizers):\n",
    "                    gradients = tape.gradient(loss, layer.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, layer.trainable_variables))\n",
    "            del tape\n",
    "            mean_loss(loss)\n",
    "            for metric in metrics:\n",
    "                metric(y_batch, y_pred)\n",
    "            print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "        print(print_status_bar(len(y_train), len(y_train), mean_loss, metrics))\n",
    "        y_val_pred = model(X_val)\n",
    "        val_loss = mean_loss(loss_fn(y_val, y_val_pred)).numpy()\n",
    "        print(f'Validation {mean_loss.name}: {val_loss}')\n",
    "        reset_metric_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "50000/50000 [==============================] - mean: 0.5451 - sparse_categorical_accuracy: 0.8080\n",
      "None\n",
      "Validation mean: 0.4453795254230499\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - mean: 0.3914 - sparse_categorical_accuracy: 0.8594\n",
      "None\n",
      "Validation mean: 0.396349161863327\n"
     ]
    }
   ],
   "source": [
    "custom_training_loop2(model, X_train_scaled, y_train, X_val_scaled, y_val, \n",
    "                     optimizers=[lower_optimizer, upper_optimizer], epochs=2, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
