{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Perceptron* is on of the simplest Artificial neural network architectures, proposed in 1957 by Frank Rosenblatt. It is based on a *threshold logic unit (TLU)* and it computes a weighted sum of its inputs\n",
    "\n",
    "$$ z = w_1x_1 + \\cdots + w_nx_n = \\textbf{x}^{\\intercal}\\textbf{w} $$\n",
    "\n",
    "then applies a step function to that sum and outputs the result: $h_w(\\textbf{x})=\\text{step}(\\textbf{x})$. One of the most common step function used is the *Heaviside step function*\n",
    "\n",
    "$$ \\text{heaviside}(z) = \\begin{cases} 0 & \\text{if } z<0 \\\\ 1 & \\text{if } z\\gt0 \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single TLU can be used for binary classification; it computes a linear combination of its inputs and if the output reaches a threshold, it outputs a positive class, otherwise outputs the negative class.\n",
    "\n",
    "A perceptron is composed of a single layer of TLUs, with each TLU connected to all the inputs. When all the neurons in a layer are connected to every neuron in the previous layer the layer is called a *fully connected* or *dense* layer. *Input Neurons* are simple inputs that output whatever they are fed and all input neurons form the *input layer*. A bias neuron is generally added, tipycally represented by a *bias neuron*, which outputs 1 all the time. (e.g. architecture pg 286 fig 10-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then write the outputs of a fully connected layer as \n",
    "$$ h_{\\textbf{W, b}}(\\textbf{X}) = \\phi(\\textbf{XW + b})$$\n",
    "Where\n",
    "- $\\textbf{X}$ is the matrix of input features (one row per instance, one col per feature)\n",
    "- $\\textbf{W}$ contains the connection weights, except the ones from the bias neuron (one row per input neuron, one column per artificial neuron in the layer)\n",
    "- $\\phi$ is called the *activation function* (when the neurons are TLU, this is a step function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron learning rule reinforces connections between neurons tha help reduce the error: the perceptron is fed one training instance at a time, and for each instance it makes its predictions. For every output neuron that produced a wrong predictions, it reinforces the connection weights from the inputs that would have contributed to the correct prediction\n",
    "\n",
    "$$ w_{i,j}^{\\text{next step}} = w_{i,j} +\\eta(y_j - \\hat{y_j})x_i$$\n",
    "\n",
    "where \n",
    "- $w_{i,j}$ is the weight between ith input neuron and jth output neuron\n",
    "- $x_i$ is the ith input value of the current training instance\n",
    "- $\\hat{y_j}$ is the output of the jth output neuron \n",
    "- $y_j$ is the target output of the jth ouptut neuron\n",
    "- $\\eta$ is the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The multilayer perceptron and backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An MLP consistis of one input layer, one or more layers of TLUs (called *hidden layers*) and one final layer of TLUs called the *output layer*. Every except the output layer includes a bias neuron and is fully connected to the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train an MLP, we use [backpropagation](https://homl.info/44). In short, it is Gradient Descent and it is able to compute the gradient of the network's error with regard to every single model parameter, thus it is able to find out how much it should tweak each connection weight and bias in order to reduce the error. This process is called *autodiff*, appendix D has more info on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how it works\n",
    "- It handles one mini-batch at a time (e.g. 32 instances) and goes through the training set multiple times, each pass is called an *epoch*\n",
    "- Each mini-batch is passed is passed to the network's input layer, which sends it to the first hidden layer. The algorithm then computes the outputs of this layer and passes it to the next layer, and so on, until we get the output of the output layer. This is called a *forward pass* and the intermediate results are saved\n",
    "- Next we calculate the network's output error (using some loss function)\n",
    "- Then it computs how much each output connection contributed to the error (done using chain rule)\n",
    "- The algorithm then measures how much of these error contributions came from each connection in the layer below until it reaches the input layer\n",
    "- Finally, it performs a gradient descent step to tweak all the connection weights in the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One change that had to be made to the original MLP architecture was replacing the step function with the logistic function $\\sigma(z) = 1 / (1 +\\exp(-z))$, this allows for gradients to be computed as it is a smooth function.\n",
    "\n",
    "Some other choices of function are:\n",
    "- Hyperbolic tan $\\tanh(z) = 2\\sigma(2z) - 1$\n",
    "\n",
    "Another S-shaped function, continues and differentiable. Its outputs are in the range -1 to 1, making each layer's output more or less centered around 0 at the beginning of training, which helps speed up convergence.\n",
    "\n",
    "- Rectified Linear unit $ReLU(z) = \\max(0,z)$\n",
    "\n",
    "Continuous but not differentiable at $z=0$, however it works very well and has become the default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions are useful because they can add non-linearity to each layer. Recall that a linear transformation of linear transformations is also linear. Using a non-linear function allows for an MLP to learn more complex patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use MLP for regression we use an output neuron for each value we want to predict. In the univariate case (e.g. predicting house price) only a single output neuron is needed. \n",
    "\n",
    "For multivariate problems, you need one output neuron per output dimension. For example to locate the center of an object in an image, you need to predict 2D coordinates, thus 2 output neurons. If you also want to place a bounding box around the object, you need two more numbers, the width and height of the object. In total, 4 output neurons.\n",
    "\n",
    "In general we do not want to use any activation function for output neurons so they are free to output any range of values. To guarantee the range of values is always positive, use ReLU or *softplus*, which is a smooth variant of ReLU: $\\text{softplus}(z) = \\log(1 + \\exp(z))$. \n",
    "Finally if we want to guarantee the predictions will fall between a range of values we can use the logistic or hyperbolic tangent function, scaling the labels to the appropriate values.\n",
    "\n",
    "The typical loss function used is MSE, however if you have a lot of outliers in your training set you may want to use the mean absolute error instead. Alternatively use [Huber loss](https://en.wikipedia.org/wiki/Huber_loss), which is a combination of both.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical regression MLP architecture\n",
    "\n",
    "| Hyperparameter | Typical value |\n",
    "|     ---        |      ---      |\n",
    "|# input neurons | One per input feature (e.g. 28x28=784 for MNIST) | \n",
    "|# hidden layers | Variable (typically 1 to 5) |\n",
    "|# neurons per hidden layers | Variable (typically 10 to 100) |\n",
    "|# output layer | 1 per prediction dimension |\n",
    "|Activation function | $\\begin{cases} \n",
    "                        \\text{None} & \\text{ for any range of values } \\\\ \n",
    "                        ReLU/\\text{softplus} & \\text{ positive outputs }\\\\\n",
    "                        \\text{logistic/tanh} & \\text{ bounded outputs}\n",
    "                        \\end{cases}$ |\n",
    "|Loss Function | MSE or MAE/Huber (if outliers)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For binary classification, we just need a single output neuron using the logistic activation function. The output will be in the range 0 - 1 and we can interpret it as an estimated class probability of the positive class. The estimated probability for the negative class is one minus that number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPs can also be used for multilabel binary classification. For example, in an e-mail classification system that tags messages as spam/ham and urgent/non-urgent we would use two output neurons with the logistic function. The first outputs the probability that the e-mail is spam and the second the probability the e-mail is urgent. \n",
    "More generally, we use one output neuron for each positive class.\n",
    "\n",
    "For multiclass calssification (e.g. identifying digit classes 0 through 9), then we need one output neuron per class and should use the softmax activation to ensure estimated probabilities are between 0-1 and they add up to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the loss function, since we're preducting probability distributions, the cross-entropy loss is generally a good choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical classification MLP architecture\n",
    "\n",
    "| Hyperparameter | Binary Classification | Multilabel Binary Classification | Multiclass Classification | \n",
    "| --- | --- | --- | --- |\n",
    "|# input neurons | One per input feature | One per input feature | One per input feature |\n",
    "|# hidden layers | Variable (typically 1 to 5) | Variable (typically 1 to 5) | Variable (typically 1 to 5) |\n",
    "|# neurons per hidden layers | Variable (typically 10 to 100) | Variable (typically 10 to 100)| Variable (typically 10 to 100)|\n",
    "|# output neurons | 1 | 1 per label | 1 per class |\n",
    "|Activation Function| Logistic | Logistic | Softmax |\n",
    "|Loss Function | Cross Entropy | Cross Entropy | Cross Entropy |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "Play around in the [Tensorflow Playground](https://playground.tensorflow.org) to get a better feeling for ANNs and explore the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing MLPs with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Image Classifier using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we will tackle Fashion MNIST, which is a drop-in replacement of MNIST. The images represent fashion items instead of digits, so each class is more diverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is loaded as ints in the range from 0 to 255. Let's create a validation set and scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000]/255.0, X_train_full[5000:]/255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to map the target values to their actual class as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using the Sequential API\n",
    "We'll start by creating a classification MLP with two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=[28,28])) # Converts inputs to 1D array\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequential API is the simplest kind of model for NNs that are just composed of a single stack of layers connected sequentially. Another way to write the same model could be as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[28,28]),\n",
    "    Dense(300, activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can vew a definition of the model by using summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model has a lot of parameters, it has a lot of flexibility to train the data. However this also means that it runs the risk of overfitting, especially when we don't have much training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view a model's Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Flatten at 0x7f613e0d8460>,\n",
       " <keras.layers.core.Dense at 0x7f613879a370>,\n",
       " <keras.layers.core.Dense at 0x7f613879a7f0>,\n",
       " <keras.layers.core.Dense at 0x7f613879aa30>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_4'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as it's weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02856481, -0.07011875,  0.01708196, ..., -0.04368379,\n",
       "        -0.00595396,  0.05870846],\n",
       "       [ 0.04723977, -0.02109544, -0.02315624, ...,  0.00892232,\n",
       "         0.05672345, -0.0205122 ],\n",
       "       [-0.06727037, -0.0411685 ,  0.02038333, ..., -0.04774668,\n",
       "        -0.03081633, -0.04496842],\n",
       "       ...,\n",
       "       [-0.06352663,  0.03185631,  0.04740191, ...,  0.00362604,\n",
       "        -0.0219669 ,  0.03039532],\n",
       "       [ 0.03102626, -0.02586513,  0.07019496, ...,  0.00816435,\n",
       "        -0.03722331, -0.05957384],\n",
       "       [ 0.06609361, -0.03666897,  0.05830039, ...,  0.05513498,\n",
       "        -0.00119662,  0.02499477]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the weights are initialized randomly (to break simmetry) and the biases set to zero. To use other initialization methods we can set the ```kernel_initializer``` or ```bias_initializer``` when creating the layer.\n",
    "\n",
    "Next we compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = 'sgd',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use ```sparse_categorical_crossentropy``` because we have sparse labels (i.e. for each instance there is only a single target class) and the classes are exclusive. If instead we had one target probability per class for each instance  (such as one-hot vectors for a single class) we'd use ```categorical_crossentropy``` instead. \n",
    "\n",
    "The optimizer set to ```sgd``` means we'll train the model using simple stochastic gradient descent. \n",
    "\n",
    "Finally, we can fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 4s 80us/step - loss: 0.7262 - accuracy: 0.7611 - val_loss: 0.5066 - val_accuracy: 0.8322\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 4s 73us/step - loss: 0.4928 - accuracy: 0.8289 - val_loss: 0.4445 - val_accuracy: 0.8532\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 4s 74us/step - loss: 0.4471 - accuracy: 0.8426 - val_loss: 0.4292 - val_accuracy: 0.8564\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 4s 73us/step - loss: 0.4203 - accuracy: 0.8529 - val_loss: 0.3952 - val_accuracy: 0.8706\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 4s 78us/step - loss: 0.3999 - accuracy: 0.8597 - val_loss: 0.3852 - val_accuracy: 0.8714\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.3812 - accuracy: 0.8656 - val_loss: 0.4074 - val_accuracy: 0.8552\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 4s 77us/step - loss: 0.3673 - accuracy: 0.8701 - val_loss: 0.4642 - val_accuracy: 0.8314\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 4s 78us/step - loss: 0.3570 - accuracy: 0.8737 - val_loss: 0.3468 - val_accuracy: 0.8802\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 4s 74us/step - loss: 0.3454 - accuracy: 0.8776 - val_loss: 0.3585 - val_accuracy: 0.8740\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 4s 75us/step - loss: 0.3363 - accuracy: 0.8787 - val_loss: 0.3336 - val_accuracy: 0.8816\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.3277 - accuracy: 0.8832 - val_loss: 0.3343 - val_accuracy: 0.8806\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 4s 73us/step - loss: 0.3211 - accuracy: 0.8848 - val_loss: 0.3629 - val_accuracy: 0.8750\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 4s 74us/step - loss: 0.3128 - accuracy: 0.8882 - val_loss: 0.3369 - val_accuracy: 0.8806\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.3059 - accuracy: 0.8904 - val_loss: 0.3428 - val_accuracy: 0.8780\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.2985 - accuracy: 0.8932 - val_loss: 0.3275 - val_accuracy: 0.8822\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.2934 - accuracy: 0.8934 - val_loss: 0.3279 - val_accuracy: 0.8822\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.2879 - accuracy: 0.8958 - val_loss: 0.3176 - val_accuracy: 0.8852\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 4s 73us/step - loss: 0.2824 - accuracy: 0.8982 - val_loss: 0.3039 - val_accuracy: 0.8932\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 4s 73us/step - loss: 0.2769 - accuracy: 0.9000 - val_loss: 0.3011 - val_accuracy: 0.8944\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 4s 76us/step - loss: 0.2718 - accuracy: 0.9033 - val_loss: 0.3006 - val_accuracy: 0.8928\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 4s 77us/step - loss: 0.2668 - accuracy: 0.9037 - val_loss: 0.3173 - val_accuracy: 0.8902\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 4s 78us/step - loss: 0.2623 - accuracy: 0.9055 - val_loss: 0.3061 - val_accuracy: 0.8900\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 4s 73us/step - loss: 0.2575 - accuracy: 0.9081 - val_loss: 0.3030 - val_accuracy: 0.8940\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 4s 73us/step - loss: 0.2534 - accuracy: 0.9080 - val_loss: 0.3439 - val_accuracy: 0.8770\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.2500 - accuracy: 0.9094 - val_loss: 0.2933 - val_accuracy: 0.8996\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 4s 72us/step - loss: 0.2452 - accuracy: 0.9114 - val_loss: 0.2940 - val_accuracy: 0.8980\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 4s 74us/step - loss: 0.2405 - accuracy: 0.9134 - val_loss: 0.3149 - val_accuracy: 0.8832\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 4s 74us/step - loss: 0.2379 - accuracy: 0.9145 - val_loss: 0.3017 - val_accuracy: 0.8912\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 4s 73us/step - loss: 0.2326 - accuracy: 0.9161 - val_loss: 0.2958 - val_accuracy: 0.8964\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 4s 79us/step - loss: 0.2297 - accuracy: 0.9173 - val_loss: 0.2963 - val_accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: instead of passing a validation set, you can also set the ```validation_split``` argument of the ```fit``` method to the ratio of the training set you want Keras to use for validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training set is very skewed, with some classes being underrepresented, it can be useful to set the ```class_weight``` parameter, this would give larger weight to underrepresented classes and a lower weight to overrepresented classes.\n",
    "\n",
    "If you need per instance weights, the ```sample_weight``` can be used. Per-instance weights can be useful if some instances are labelled by experts while others were labeled using a crowdsourcing platform: we might want to give more weights to the former."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the ```history.history``` to access the loss and accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(10, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the model performed better on the validation set than on the training set at the beginning, but this is not true.\n",
    "\n",
    "The validation error is computed at the *end* of each epoch while the training error is computed using a running mean *during* each epoch. So the training curve should actually be shifted half an epoch to the left. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
